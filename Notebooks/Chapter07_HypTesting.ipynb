{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQy1bAvmpuRVSv9fvIaRyG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravichas/bifx-546/blob/main/Notebooks/Chapter07_HypTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7 Hypothesis Testing\n",
        "\n",
        "Often Data Scientists want to test whether a certain hypothesis is likely to be true.\n",
        "\n",
        "\n",
        "Hypothesis: A claim that we want to test\n",
        "\n",
        "**Null Hypothesis** (H$_0$)\n",
        "\n",
        "* Currently accepted value for a parameter (ex., mean)\n",
        "\n",
        "**Alternate Hypothesis** (H$_a$) or Research Hypothesis\n",
        "\n",
        "* Involves the claim to be tested"
      ],
      "metadata": {
        "id": "kSQrzFaCCMtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another way to look at this is\n",
        "\n",
        "## Hypthesis Testing:\n",
        "\n",
        "* Formal method DS use to decide whether a claim about the world is supported by data or not\n",
        "\n",
        " **The Process**\n",
        "  * **Start with a claim you want to test**\n",
        "    * Example: \"The coin is fair\" (50/50 chance of H/T)\n",
        "  * A**ssume the claim is true, and figure out what you would expect to see**\n",
        "    * if the coin is fair, flipping it 1000 times should give you 500 Hs (may be 48, may be 53, but somewhere close)\n",
        "    * We know the pattern of what \"randomness\" looks like when the coin is fair\n",
        "  * **Collect actual data**\n",
        "    * Flip the coin 1000 times and count: you got 991 Hs\n",
        "  * **Ask: \"How weird is what I actually saw?\"**\n",
        "    * If the coin were fair, getting 900 heads out of 1000 would be extremely unlikely\n",
        "    * This suggests our original assumption (fair coin) is probably wrong\n",
        "  * **Make a decision**\n",
        "    * If your data looks normal/expected --> The HYPOTHESIS is probably true\n",
        "    * If your data looks weird/unlikely --> the HYPOTHESIS is probably false.\n"
      ],
      "metadata": {
        "id": "Cy-rGaizzgLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to Tibshirani et al book on Statistical Learning, Hyp Testing is a rigorous stat framework for answering simple \"yes-no\" questions about the data"
      ],
      "metadata": {
        "id": "qYxbIvmU_G4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example\n",
        "\n",
        "We operate a candy-bar manufacturing plant and recently upgraded our production machines. The factory quality engineer now claims that the average weight of our candy bars is no longer 250 grams. To evaluate this claim, we set up the following hypotheses:\n",
        "\n",
        "\n",
        "$$ H_0: \\mu = 250 \\quad \\text{(The factory still produces candy bars with a mean weight of 250 grams.)} $$ (default belief)\n",
        "\n",
        "$$ H_a: \\mu \\ne 250 \\quad \\text{(The mean weight has changed from 250 grams after the upgrades.)} $$\n",
        "\n",
        "Note that $H_{0}$ and $H_{a}$ are mathematical opposites. For example, $H_a$ is whatever that $H_0$ is not."
      ],
      "metadata": {
        "id": "3MB70EujDWFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that the null is true unless the data proves otherwise.\n",
        "\n",
        "Let us explore the possible outcomes for this test:\n",
        "* Reject Null Hyp\n",
        "* Fail to **Reject Null Hypothesis** (difficult to prove something is true)\n",
        "\n",
        "Think of US judicial system while reading through this.\n"
      ],
      "metadata": {
        "id": "4_y9-z0EEjc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How can we carry out the test?\n",
        "\n",
        "* First we need a $H_0$ (default belief; nothing has changed after the upgrade) and $H_a$. Note $H_0$ is the baseline assumption.\n",
        "* We need something called Test Statistic (that provides evidence for rejecting the $H_0$. This is calculated from sample data and is used to either reject the $H_0$ or **Fail** to reject the $H_0$\n",
        "$$ T = \\frac{\\bar{x} - 250 } {s/\\sqrt{n}} $$\n",
        "Where:\n",
        "  * $\\bar{x}$ = sample mean weight\n",
        "  * s = samp SD\n",
        "  * n = sample size\n",
        "Note:\n",
        "  * T = 0 --> The sample mean equals 250 exactly --> Consistent with $H_0$\n",
        "  * T large postive: sample mean is far above 250\n",
        "  * T is large negative:  sample mean is far below 250\n",
        "  * large |T| means stronger evidence against $H_0$. The test statistic summarizes how consistent the data are with $H_0$.\n",
        "* We then compute a $p-value$ that measures the probability of having observed a comparable or extrement value of the **test statistic** under the $H_0$. In essence, p-value answers:\n",
        "  * **If the true mean is 250 gms ($H_0$ is true), how unusual is the sample we observed?**\n",
        "  * Note, If the null hypothesis holds, the test statistic T approximately follows a t-distribution (or approximately N(0,1) for large n).\n",
        "  * Note: \"$H_0$ holds\" means:\n",
        "    * The true weight of all candy bars produced by the factory (entire population) is actually 250 grams.\n",
        "* Finally using the p-value we either \"reject the $H_0$\" or \"Fail to reject\" $H_0$\n",
        "  * Let us consider the example: If $T=233$. This means that our sample mean is 2.33 SD away from 250 grams. This value in the distribution lies at the extreme and lies outside of $\\pm$ 2.33 that means only 2% of samples would give such an extreme result if $\\mu = 250$ were actually true. Hence, p=0.02 (one-sided) and p=0.02*2 = 0.04\n",
        "  * We need to decide whether 4% small? We also have a pre-determined cutoff ($\\alpha$). Using $\\alpha$, we Reject $H_0$ if p $\\lt$ 0.05, Fail to reject if $H_0$ if p >= 0.05. Based on this, we reject the null-hypothesis at $alpa$ = 0.05"
      ],
      "metadata": {
        "id": "tWfEy6jEFaqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Errors:\n",
        "\n",
        "* **Type 1 Error (False Postive)**: $H_0$ is actually true (true mean is still 250g). But, we reject $H_0$. We conclude the machine changed the mean weight even though it did not.\n",
        "  * Consequences:\n",
        "    * We stop production\n",
        "    * we recalibrate the machine\n",
        "    * blame the upgrade\n",
        "    * but nothing was wrong\n",
        "  * Are Type-1 errors bad?\n",
        "* **Type II Error (False Negative):** $H_{0}$ is actually false (mean has really changed). But, we failed to reject the Null.  \n",
        "    * Consequences:\n",
        "        * We continue production without noticing\n",
        "        * Candy. bars size over/under-filled\n",
        "        * Customers may complain\n",
        "        * Quality issues arise\n",
        "      * Are Type-II errors bad?\n",
        "* **Power of the test**\n",
        "  * Power = 1 - Type II error rate\n",
        "    * Our test correctly detects real changes\n",
        "* **Trade-off between Type1/TypeII errors** and the choice of $\\alpha$ ?\n",
        "  * You cannot minimize both errors simultaneously\n",
        "    * Lowering Type I error increase Type II error\n",
        "    * Lowering Type II increase Type I error"
      ],
      "metadata": {
        "id": "GzrE-Fn-Musr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistically Significant  (SS)\n",
        "\n",
        "A result is SS when\n",
        "\n",
        "* p-value $\\lt$ $\\alpha$\n",
        "\n",
        "Note:\n",
        "* SS does not mean\n",
        "  * effect is big\n",
        "  * result is true\n",
        "  * more important"
      ],
      "metadata": {
        "id": "8CgxXXTOIgL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of testing whether the coin fair\n",
        "\n",
        "if we want to test whether the coin (p = prob of landing Hs) we have is fair.  \n",
        "\n",
        "$$ H_0 : p = 0.5 $$\n",
        "$$ H_A : p \\ne 0.5 $$"
      ],
      "metadata": {
        "id": "bY9s-Vf_3YT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic ideas\n",
        "\n",
        "* Bernoulli Trial (Single flip)\n",
        "  * Each individuval flip is a \"Bernoulli trial\"\n",
        "  * Only two outcomes: H (Sucess) or T (failure)\n",
        "  * Probability of Hs = p (for a fair coin, p = 0.5)\n",
        "* Binomial Distribution (Multiple Independent Flips)\n",
        "  * A reference table/curve that tells you probabilities\n",
        "  * Created mathematically (not from your experiemtn)\n",
        "  * Shows what outcomes to expect IF the coin is fair (p=0.5)\n",
        "  ### Connection to Bernoulli\n",
        "    * Each of the flip is a Bernoulli trial\n",
        "    * X = number of Hs in one trial\n",
        "    * X follows a Binomial(n=100, p=0.5) distribution\n",
        "  ### What Binomial Distribution Tells You:\n",
        "    * P(X=0) = Prob of 0 Hs in 100 flips\n",
        "    * ...\n",
        "    * P(X=65) = Prob of 65 Hs in 100 flips\n",
        "    * etc.\n",
        "\n",
        "  $$ P(X = k) = C(n, k) \\times p^{k} \\times (1-p)^{(n-k)} $$\n",
        "  where $C(n,k) = \"n choose k\" = combinations\n",
        "\n",
        "* Normal Approximation (when n is large; number of times to repeat the bernoulli trial)\n",
        "\n"
      ],
      "metadata": {
        "id": "b2AOyuGKq3KK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Experiment\n",
        "  * Flip a coin = 100 times\n",
        "  * Cont the result, X = 65 Hs (example)\n",
        "  * One experiment. One Number: 65\n",
        "* Question\n",
        "  * Is this coin fair, or is it biased?\n",
        "\n",
        "# Using a pre-existing Reference Distribution\n",
        "\n",
        "  * Mathematicians already derived a reference distribution for us\n",
        "    * They derived the Binomial(n=100, p=0.5) distribution\n",
        "    * This distribution shows, \"If the coin is fair, here is likely each outcome is\"\n",
        "    * It tells us the probability of getting 0 Hs, 1Hs, ....100 Hs.\n",
        "  * If we take one result from our experiment (X = 65) and compare it with the reference\n",
        "    * Look at our pre-existing Binomial Distribution\n",
        "    * Ask: Where does my result (H=65) fall on this distribution?\n",
        "    * Find: \"Getting 65 or more Hs happens only 0.3% of the time if the coin is fair\n",
        "  * Make a decision\n",
        "    * Since 65 is unlikely under the \"fair coin\" distribution\n",
        "    * Conclude: The coin is biased\n"
      ],
      "metadata": {
        "id": "-5Hoq8yVtiWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean\n",
        "\n",
        "$$ E[[X] = \\sum k \\times P(X=k)  \\text{   for k = 0 to n} $$\n",
        "\n",
        "After working with Algebra, we get\n",
        "\n",
        "E[X] = np\n",
        "\n",
        "Example\n",
        "\n",
        "* If we flip 100 coin (n = 100)\n",
        "* Each has p = 0.5 chance of Hs\n",
        "* Expected Hs $\\mu$ = 100 * 0.5 = 50\n",
        "\n",
        "# SD\n",
        "\n",
        "$$ \\text{Var}[X] = E[X^2] - (E[X])^2 $$\n",
        "\n",
        "After working through Algebra,\n",
        "\n",
        "$$ \\text{Var}[X] = \\sqrt{np(1-p)} $$\n",
        "\n",
        "# Example\n",
        "\n",
        "* n= 100, p = 0.5\n",
        "* Variance = 100 * 0.5 * 0.5 = 25\n",
        "* SD: $\\sigma$ = $\\sqrt{25}$ = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "7xoQ5e_kAsdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As n increases, Binomial(n, p) --> Normal Distribution\n",
        "\n",
        "The limiting normal has the SAME mean (np) and variance (np(1-p))\n",
        "\n",
        "When np$\\ge$10 and n(1-p) $\\ge$ 10, he approximation is accurate enough for practical use."
      ],
      "metadata": {
        "id": "Pl0pLjLtDbdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Course setup: safe clone + cd + import path ====\n",
        "import os\n",
        "import sys\n",
        "\n",
        "REPO_URL = \"https://github.com/joelgrus/data-science-from-scratch.git\"\n",
        "REPO_DIR = \"data-science-from-scratch\"\n",
        "\n",
        "# 1. If we're *anywhere inside* the repo, move to the parent directory first\n",
        "cwd = os.getcwd()\n",
        "if REPO_DIR in cwd.split(os.sep):\n",
        "    parts = cwd.split(os.sep)\n",
        "    # Walk up until we are at .../data-science-from-scratch\n",
        "    while parts and parts[-1] != REPO_DIR:\n",
        "        parts.pop()\n",
        "    # Now go to the directory *above* the repo\n",
        "    parent_dir = os.sep.join(parts[:-1]) or \"/\"\n",
        "    os.chdir(parent_dir)\n",
        "    print(f\"Moved to parent directory: {os.getcwd()}\")\n",
        "\n",
        "# 2. Clone only if needed\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(\"Cloning repo...\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(f\"{REPO_DIR} already exists — skipping clone.\")\n",
        "\n",
        "# 3. cd into the repo (this is where you'll live most of the time)\n",
        "%cd {REPO_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtMITU0xLp5k",
        "outputId": "6314f784-54ca-41aa-9bb2-310aac6552c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved to parent directory: /content\n",
            "data-science-from-scratch already exists — skipping clone.\n",
            "/content/data-science-from-scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import math\n",
        "\n",
        "def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:\n",
        "  \"\"\" Returns mu and sigma corresponding to a Binomial(n, p) \"\"\"\n",
        "  mu = p * n\n",
        "  sigma = math.sqrt(p * (1-p) * n)\n",
        "  return mu, sigma\n"
      ],
      "metadata": {
        "id": "KxFd-cmR28h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scratch.probability import normal_cdf\n",
        "# The normal cdf _is_ the probability the variable is below a threshold\n",
        "normal_probability_below = normal_cdf\n",
        "# It's above the threshold if it's not below the threshold\n",
        "def normal_probability_above(lo: float, mu: float = 0, sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is greater than lo.\"\"\"\n",
        "  return 1 - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# It's between if it's less than hi, but not less than lo\n",
        "def normal_probability_between(lo: float, hi: float, mu: float = 0,\n",
        "                               sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is between lo and hi.\"\"\"\n",
        "  return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# It's outside if it's not between\n",
        "def normal_probability_outside(lo: float, hi: float, mu: float = 0,\n",
        "                               sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is not between lo and hi.\"\"\"\n",
        "  return 1 - normal_probability_between(lo, hi, mu, sigma)"
      ],
      "metadata": {
        "id": "gQu8oBiCHTJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Comparison"
      ],
      "metadata": {
        "id": "v9Quq4kKQGXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Interval\n",
        "\n",
        "A confidence interval (CI) provides a range of plausible values for a population parameter, such as a mean.\n",
        "\n",
        "If you compute a 95% CI for the mean weight of candy bars:\n",
        "\n",
        "$$ \\bar{x} \\pm 1.96 \\cdot \\frac{s}{\\sqrt{n}} $$\n",
        "\n",
        "This gives a range such that:\n",
        "\n",
        "If you repeated the sampling process infinitely many times, 95% of the intervals would contain the true mean μ.\n",
        "\n",
        "\n",
        "* A CI does not say “there is a 95% chance μ is in this interval.”\n",
        "* Instead: “This method captures μ in 95% of repeated experiments.”\n",
        "* The CI width reflects uncertainty. Smaller width = more precision."
      ],
      "metadata": {
        "id": "_vT3ji3AVDkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vp13NWYkZt6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F8q0RSBZZt2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose:\n",
        "* Sample mean = 247g\n",
        "    * s1 = [243.1, 250.9], s2 = [246.8, 254.2] ....  sn\n",
        "    * Each of these is a CI from a sample\n",
        "    * $I1, I2, I3, I4, ...$ from $s1, s2, s3, s4, ... $\n",
        "    * Of all these intervals 95% will contain the true mean $\\mu$ and 5% will miss. We never know which interval is correct, but th procedure succeeds 95% of the time\n",
        "\t* Standard deviation = 20g\n",
        "\t* n = 100\n",
        "\n",
        "95% CI:\n",
        "\n",
        "$247 \\pm 1.96 \\cdot \\frac{20}{10} = 247 \\pm 3.92$\n",
        "\n",
        "That is:\n",
        "\n",
        "[243.08,\\; 250.92]\n",
        "\n",
        "Because 250g is inside this interval → we fail to reject H₀ at α = 0.05.\n",
        "\n",
        "CI ↔ Hypothesis Test\n",
        "\n",
        "* A 95% CI and a two-sided hypothesis test at α = 0.05 give the same decision:\n",
        "* If the CI excludes 250 → reject H₀\n",
        "* If the CI includes 250 → fail to reject H₀\n"
      ],
      "metadata": {
        "id": "hONEmOKEWxAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CI Assumptions:\n",
        "* Independent observations (selected independent of the others)\n",
        "* Accurate Data (non biased)\n",
        "*"
      ],
      "metadata": {
        "id": "vp5vSXVJcgdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# p-Hacking\n",
        "\n",
        "With some help, you can find the \"significant\" hypothesis if you test enough hypotheses against your dataset\n",
        "\n",
        "To do good science, decide on your hypotheses before looking at the data."
      ],
      "metadata": {
        "id": "OTrKsLZ-fhKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p-Hacking\n",
        "import random\n",
        "\n",
        "from typing import List\n",
        "def run_experiment() -> List[bool]:\n",
        "  \"\"\"Flips a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
        "  return [random.random() < 0.5 for _ in range(1000)]\n",
        "\n",
        "def reject_fairness(experiment: List[bool]) -> bool:\n",
        "  \"\"\"Using the 5% significance levels\"\"\"\n",
        "  num_heads = len([flip for flip in experiment if flip])\n",
        "  return num_heads < 469 or num_heads > 531\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "experiments = [run_experiment() for _ in range(1000)]\n",
        "num_rejections = len([experiment\n",
        "                      for experiment in experiments\n",
        "                      if reject_fairness(experiment)])\n",
        "assert num_rejections == 46"
      ],
      "metadata": {
        "id": "fbjCkqnPecSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A/B Testing\n",
        "\n",
        "Check the book/Book-Github for details"
      ],
      "metadata": {
        "id": "YNMziwYxfdDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here is a basic overview of A/B Testing:\n",
        "\n",
        "**What we estimate in an A/B test**\n",
        "\n",
        "You have two variants:\n",
        "\n",
        "* A (control) has some true (unknown) parameter $\\theta_A$\n",
        "* B (treatment) has some true (unknown) parameter $\\theta_B$\n",
        "\n",
        "What $\\theta$ is depends on the metric:\n",
        "\n",
        "**If the metric is a conversion rate (most common)**\n",
        "\n",
        "* $\\theta_A = p_A$ = true conversion probability for A\n",
        "* $\\theta_B = p_B$ = true conversion probability for B\n",
        "\n",
        "**Primary estimand (what we care about):**\n",
        "\n",
        "* Difference: $\\Delta = p_B - p_A $(absolute lift)\n",
        "* Ratio: RR = $\\frac{p_B}{p_A}$ (relative lift)\n",
        "* Or log-odds difference if you prefer modeling convenience.\n",
        "\n",
        "**If the metric is continuous (revenue, time-on-site, etc.)**\n",
        "\n",
        "* $\\theta_A = \\mu_A$ = true mean outcome for A\n",
        "* $\\theta_B = \\mu_B$ = true mean outcome for B\n",
        "Often also the variance \\sigma^2.\n",
        "\n",
        "**Primary estimand:**\n",
        "\n",
        "* $\\Delta = \\mu_B - \\mu_A$"
      ],
      "metadata": {
        "id": "efZpcHWGXj4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an A/B test we estimate $\\hat p_A$ and $\\hat p_B$, compute the observed difference $\\hat{\\Delta}$, then under the null hypothesis of no difference we calculate a p-value: the chance of seeing a difference at least as extreme as $\\hat\\Delta$; if $p \\le \\alpha$ we reject the null."
      ],
      "metadata": {
        "id": "T9pFVC97_zfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# another way of looking at A/B Testing\n",
        "\n",
        "It’s the population of eligible users who could be in the experiment (e.g., all visitors during the test period who meet criteria).\n",
        "\n",
        "You **split that one population randomly into two groups**:\n",
        "* **Group A:** users assigned A\n",
        "* **Group B:** users assigned B\n",
        "\n",
        "**Each group has its own conversion probability because the experience differs.**\n",
        "\n",
        "**Quick example**\n",
        "\n",
        "If **1,000 **users see A and 50 buy:\n",
        "* $\\hat{p_A} = 50/1000 = 5\\%$\n",
        "\n",
        "If **1,000** users see B and 60 buy:\n",
        "* $\\hat{p_B} = 60/1000 = 6\\%$\n",
        "\n",
        "Then lift is 1$\\%$ point.\n",
        "\n",
        "In a classical (frequentist) A/B test, **we do not assume the true difference ($p_A - p_B$) is random and normal**.\n",
        "\n",
        "**What’s random is the estimate from data**\n",
        "\n",
        "We treat the observed/sample difference\n",
        "$\\hat{\\Delta} = \\hat{p_B} - \\hat{p_A}$\n",
        "as a random variable, because it changes **from sample to sample**.\n",
        "\n",
        "The true parameters $p_A$, $p_B$ (and $\\Delta = p_B - p_A$) are treated as fixed but unknown.\n",
        "\n",
        "Carry out Hyp Testing\n",
        "\n",
        "H0: $p_A - p_B$ = 0\n",
        "\n",
        "HA: Not zero"
      ],
      "metadata": {
        "id": "64uBI0XuPxa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Inference"
      ],
      "metadata": {
        "id": "8kb_J4REZ5Gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What we were doing before (classical inference)\n",
        "\n",
        "Up to now, we’ve been doing things like:\n",
        "\n",
        "`“If the null hypothesis were true, there’s only a 3% chance we would see data this extreme.”`\n",
        "\n",
        "Key idea:\n",
        "* We assume a hypothesis is true (usually “no effect”).\n",
        "* Then we ask how surprising the data would be under that assumption.\n",
        "\n",
        "So the probability statements are about data, not about the unknown parameter.\n",
        "\n",
        "That’s what a p-value is:\n",
        "\n",
        "$$P(\\text{data} \\mid \\text{null hypothesis})$$\n",
        "\n",
        "Note:\n",
        "“If this hypothesis were true, what distribution would the data come from?”\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fwX2uuFHXmos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Framework     | What is treated as random? | What the probability is about |\n",
        "|---------------|----------------------------|--------------------------------|\n",
        "| Frequentist   | Data (before observing it) | $ P(\\text{data} \\mid \\text{hypothesis}) $ |\n",
        "| Bayesian      | Parameter                  | $ P(\\text{parameter} \\mid \\text{data})$ |"
      ],
      "metadata": {
        "id": "Qqc2y8D1bKOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. The Bayesian shift: what changes?\n",
        "\n",
        "Bayesian inference flips the perspective.\n",
        "\n",
        "**Instead of treating the data as random and the parameters as fixed-but-unknown, we:**\n",
        "\n",
        "Treat the unknown parameters themselves as uncertain.\n",
        "\n",
        "So now:\n",
        "* The parameter (like the coin’s probability of heads) is modeled as a random variable\n",
        "* We describe our uncertainty about it with a probability distribution\n",
        "\n",
        "This lets us make probability statements like:\n",
        "\n",
        "`“There’s a 95% probability that the true parameter lies in this range.”`\n",
        "\n",
        "**That is not allowed in classical hypothesis testing.**"
      ],
      "metadata": {
        "id": "cFisODbdZqmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. The three-step Bayesian workflow (high level)\n",
        "\n",
        "**Step 1:** Prior — what you believe before data\n",
        "\n",
        "You start with a prior distribution for the unknown parameter.\n",
        "\n",
        "In the coin example:\n",
        "* The parameter is p: the probability of heads\n",
        "* **Since p must be between 0 and 1, we use a Beta distribution**\n",
        "\n",
        "Beta(\\alpha,\\beta) distribution, the probability density is\n",
        "\n",
        "$$f(x)=\\frac{1}{B(\\alpha,\\beta)}\\,x^{\\alpha-1}(1-x)^{\\beta-1}, \\quad 0\\le x\\le 1$$\n",
        "\n",
        "## Why Beta Distribution?\n",
        "\n",
        "The Beta distribution is flexible:\n",
        "* It only lives on [0,1]\n",
        "* Its shape reflects your belief\n",
        "\n",
        "Interpretation of Beta($\\alpha,\\beta$):\n",
        "* **Center (roughly):** $\\alpha/(\\alpha+\\beta)$\n",
        "* **Strength of belief:** larger $\\alpha$,$\\beta$ = more confidence\n",
        "\n",
        "Examples:\n",
        "* **Beta(1,1)**: completely agnostic (uniform); when $\\alpha$ = $\\beta$ = 1, this will lead to 1/B(1,1)\n",
        "B(1,1)=\\int_0^1 1\\,dx = 1. So the density becomes:\n",
        "$$f(x)=1 \\quad \\text{for } 0\\le x\\le 1$$\n",
        "* **Beta(55,45)**: belief that $p \\approx 0.55$, with some confidence\n",
        "* **Beta(30,10)**: belief that $p$ is high (around 0.75)\n",
        "\n",
        "#Important:\n",
        "The prior is not saying the value is random in reality — it encodes your uncertainty.\n",
        "\n"
      ],
      "metadata": {
        "id": "YaW0ESYRcrfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Step 2: Data — what you observe\n",
        "\n",
        "You flip the coin:\n",
        "* Observe h heads\n",
        "* Observe t tails\n",
        "\n",
        "This data has a Binomial structure:\n",
        "* Given a value of p, some outcomes are more likely than others\n",
        "\n",
        "This part answers:\n",
        "\n",
        "“If the true probability were p, how likely is this data?”\n",
        "\n",
        "That’s called the likelihood.\n",
        "\n",
        "#5. Step 3: Posterior — updated belief after data\n",
        "\n",
        "Bayes’ theorem combines:\n",
        "* prior belief\n",
        "* data evidence\n",
        "\n",
        "## Result:\n",
        "\n",
        "The posterior distribution for p\n",
        "\n",
        "In this special case:\n",
        "* Beta prior + Binomial data → Beta posterior\n",
        "* This is called a conjugate prior\n",
        "\n",
        "Update rule:\n",
        "$\\text{Posterior} = \\text{Beta}(\\alpha + h,\\ \\beta + t)$\n",
        "\n",
        "Interpretation:\n",
        "* Prior contributes “pseudo-observations”\n",
        "* Data adds real observations\n",
        "\n",
        "#6. Why different priors give different posteriors (at first)\n",
        "\n",
        "Example: 10 flips, 3 heads\n",
        "* Uniform prior → posterior near 0.30\n",
        "* Strong “fair coin” prior → posterior pulled toward 0.50\n",
        "* Strong “biased coin” prior → posterior pulled toward 0.75\n",
        "\n",
        "Same data, different conclusions — because beliefs differed before data.\n",
        "\n",
        "This is the main philosophical objection people raise.#\n",
        "\n",
        "#7. Why priors matter less with lots of data\n",
        "\n",
        "As data increases:\n",
        "* The data overwhelms the prior\n",
        "* All reasonable priors lead to nearly the same posterior\n",
        "\n",
        "Seeing 1,000 heads out of 2,000 flips will convince almost everyone the coin is near 0.5.\n",
        "\n",
        "So:\n",
        "* Priors matter most with small samples\n",
        "* Priors matter least with large samples\n",
        "\n",
        "# 8. What Bayesian inference lets you say (this is the payoff)\n",
        "\n",
        "Now you can say things like:\n",
        "* “There is a 95% probability that p lies between 0.49 and 0.51.”\n",
        "* “There is only a 5% probability that the coin is approximately fair.”\n",
        "\n",
        "These are direct probability statements about parameters.\n",
        "\n",
        "Contrast with classical:\n",
        "* “If the coin were fair, data this extreme would occur only 5% of the time.”\n",
        "\n",
        "Same numbers, very different meaning\n",
        "\n",
        "# 9. Why this is controversial\n",
        "\n",
        "Two reasons:\n",
        "\t1.\tSubjectivity: choice of prior\n",
        "\t2.\tComplexity: math and computation (though software solves this now)\n",
        "\n",
        "Because of this, many textbooks teach Bayesian ideas conceptually but rely on frequentist tools in practice.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hS9gAbBAdwwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One-paragraph summary\n",
        "\n",
        "**Classical inference** makes probability statements about data assuming a hypothesis is true. **Bayesian inference** instead treats the unknown parameter as uncertain, starts with a prior belief, updates it with data using Bayes’ theorem, and produces a posterior distribution. This lets us make direct probability statements about the parameter itself, which is intuitive but depends on the choice of prior.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3JKI16Qadzhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What Bayesian inference estimates\n",
        "\n",
        "Bayes gives you a distribution over the unknowns after seeing data:\n",
        "\n",
        "$p(\\theta_A,\\theta_B \\mid \\text{data})$\n",
        "\n",
        "From that you compute the quantities you actually want:\n",
        "\n",
        "1) Probability B is better than A, $P(\\Delta > 0 \\mid \\text{data})$\n",
        "\n",
        "  This is the Bayesian analog of “is B better?” (but it’s a probability statement).\n",
        "\n",
        "2) Size of the effect (with uncertainty)\n",
        "\n",
        "  Posterior for $\\Delta$, plus a credible interval:\n",
        "\t•\te.g. 95% credible interval for \\Delta\n",
        "\n",
        "3) Expected loss / decision-focused quantities\n",
        "\n",
        "If shipping the wrong variant has cost, you can estimate:\n",
        "* $P(\\Delta > \\delta)$ for a minimum meaningful lift $\\delta$\n",
        "* expected regret if you choose B vs A\n",
        "  * expected revenue gain, etc.\n",
        "\n",
        "Concrete example: binary conversions\n",
        "\n",
        "Suppose:\n",
        "* $A: x_A \\text{ conversions out of } n_A$\n",
        "* $B: x_B \\text{ conversions out of } n_B$\n",
        "\n",
        "# Bayesian model:\n",
        "* $p_A \\sim \\text{Beta}(\\alpha,\\beta)$\n",
        "* $p_B \\sim \\text{Beta}(\\alpha,\\beta)$\n",
        "* $Data: x_A \\sim \\text{Binomial}(n_A,p_A)$, same for B\n",
        "\n",
        "# Posterior:\n",
        "* $p_A \\mid data \\sim \\text{Beta}(\\alpha+x_A,\\beta+n_A-x_A)$\n",
        "* $p_B \\mid data \\sim \\text{Beta}(\\alpha+x_B,\\beta+n_B-x_B)$\n",
        "\n",
        "Then compute \\Delta = p_B - p_A (by sampling) and report:\n",
        "* $P(\\Delta>0)$\n",
        "* credible interval for $\\Delta$\n",
        "* $P(\\Delta>\\delta)$ if you have a threshold\n"
      ],
      "metadata": {
        "id": "vn6tQVsQhsm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What’s the difference vs Bayesian inference?\n",
        "\n",
        "###The big difference: what is random?\n",
        "\n",
        "**Frequentist (classic A/B testing):**\n",
        "* Treat $p_A$, $p_B$ as fixed but unknown constants.\n",
        "* Treat the data as random because you could repeat the experiment.\n",
        "\n",
        "**Bayesian:**\n",
        "* Treat $p_A$, $p_B$ as unknown quantities with a probability distribution (a prior).\n",
        "* After seeing data, update to a posterior distribution."
      ],
      "metadata": {
        "id": "7INWRf7lh6Oj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv6pjJoyCEoh"
      },
      "outputs": [],
      "source": []
    }
  ]
}