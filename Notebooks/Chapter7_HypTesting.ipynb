{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTdYIs4ca8TyctW5NMpaJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravichas/bifx-546/blob/main/Notebooks/Chapter7_HypTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7 Hypothesis Testing\n",
        "\n",
        "Often Data Scientists want to test whether a certain hypothesis is likely to be true.\n",
        "\n",
        "\n",
        "Hypothesis: A claim that we want to test\n",
        "\n",
        "**Null Hypothesis** (H$_0$)\n",
        "\n",
        "* Currently accepted value for a parameter (ex., mean)\n",
        "\n",
        "**Alternate Hypothesis** (H$_a$) or Research Hypothesis\n",
        "\n",
        "* Involves the claim to be tested"
      ],
      "metadata": {
        "id": "kSQrzFaCCMtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to look at this is\n",
        "\n",
        "Hypthesis Testing:\n",
        "\n",
        "* Formal method DS use to decide whether a claim about the world is supported by data or not\n",
        "\n",
        " **The Process**\n",
        "  * **Start with a claim you want to test **\n",
        "    * Example: \"The coin is fair\" (50/50 chance of H/T)\n",
        "  * A**ssume the claim is true, and figure out what you would expect to see **\n",
        "    * if the coin is fair, flipping it 1000 times should give you 500 Hs (may be 48, may be 53, but somewhere close)\n",
        "    * We know the pattern of what \"randomness\" looks like when the coin is fair\n",
        "  * **Collect actual data**\n",
        "    * Flip the coin 1000 times and count: you got 991 Hs\n",
        "  * **Ask: \"How weird is what I actually saw?\"**\n",
        "    * If the coin were fair, getting 900 heads out of 1000 would be extremely unlikely\n",
        "    * This suggests our original assumption (fair coin) is probably wrong\n",
        "  * **Make a decision**\n",
        "    * If your data looks normal/expected --> The HYP is probably true\n",
        "    * If your data looks weird/unlikely --> the HYP is probably false.\n"
      ],
      "metadata": {
        "id": "Cy-rGaizzgLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to Tibshirani et al book on Statistical Learning, Hyp Testing is a rigorous stat framework for answering simple \"yes-no\" questions about the data"
      ],
      "metadata": {
        "id": "qYxbIvmU_G4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example\n",
        "\n",
        "We operate a candy-bar manufacturing plant and recently upgraded our production machines. The factory quality engineer now claims that the average weight of our candy bars is no longer 250 grams. To evaluate this claim, we set up the following hypotheses:\n",
        "\n",
        "\n",
        "$$ H_0: \\mu = 250 \\quad \\text{(The factory still produces candy bars with a mean weight of 250 grams.)} $$ (default belief)\n",
        "\n",
        "$$ H_a: \\mu \\ne 250 \\quad \\text{(The mean weight has changed from 250 grams after the upgrades.)} $$\n",
        "\n",
        "Note that $H_{0}$ and $H_{a}$ are mathematical opposites. For example, $H_a$ is whatever that $H_0$ is not."
      ],
      "metadata": {
        "id": "3MB70EujDWFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that the null is true unless the data proves otherwise.\n",
        "\n",
        "Let us explore the possible outcomes for this test:\n",
        "* Reject Null Hyp\n",
        "* Fail to **Reject Null Hypothesis** (difficult to prove something is true)\n",
        "\n",
        "Think of US judicial system while reading through this.\n"
      ],
      "metadata": {
        "id": "4_y9-z0EEjc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How can we carry out the test?\n",
        "\n",
        "* First we need a $H_0$ (default belief; nothing has changed after the upgrade) and $H_a$. Note $H_0$ is the baseline assumption.\n",
        "* We need something called Test Statistic (that provides evidence for rejecting the $H_0$. This is calculated from sample data and is used to either reject the $H_0$ or **Fail** to reject the $H_0$\n",
        "$$ T = \\frac{\\bar{x} - 250 } {s/\\sqrt{n}} $$\n",
        "Where:\n",
        "  * $\\bar{x}$ = sample mean weight\n",
        "  * s = samp SD\n",
        "  * n = sample size\n",
        "Note:\n",
        "  * T = 0 --> The sample mean equals 250 exactly --> Consistent with $H_0$\n",
        "  * T large postive: sample mean is far above 250\n",
        "  * T is large negative:  sample mean is far below 250\n",
        "  * large |T| means stronger evidence against $H_0$. The test statistic summarizes how consistent the data are with $H_0$.\n",
        "* We then compute a $p-value$ that measures the probability of having observed a comparable or extrement value of the **test statistic** under the $H_0$. In essence, p-value answers:\n",
        "  * **If the true mean is 250 gms ($H_0$ is true), how unusual is the sample we observed?**\n",
        "  * Note, If the null hypothesis holds, the test statistic T approximately follows a t-distribution (or approximately N(0,1) for large n).\n",
        "  * Note: \"$H_0$ holds\" means:\n",
        "    * The true weight of all candy bars produced by the factory (entire population) is actually 250 grams.\n",
        "* Finally using the p-value we either \"reject the $H_0$\" or \"Fail to reject\" $H_0$\n",
        "  * Let us consider the example: If $T=233$. This means that our sample mean is 2.33 SD away from 250 grams. This value in the distribution lies at the extreme and lies outside of $\\pm$ 2.33 that means only 2% of samples would give such an extreme result if $\\mu = 250$ were actually true. Hence, p=0.02 (one-sided) and p=0.02*2 = 0.04\n",
        "  * We need to decide whether 4% small? We also have a pre-determined cutoff ($\\alpha$). Using $\\alpha$, we Reject $H_0$ if p $\\lt$ 0.05, Fail to reject if $H_0$ if p >= 0.05. Based on this, we reject the null-hypothesis at $alpa$ = 0.05"
      ],
      "metadata": {
        "id": "tWfEy6jEFaqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Errors:\n",
        "\n",
        "* Type 1 Error (False Postive): $H_0$ is actually true (true mean is still 250g). But, we reject $H_0$. We conclude the machine changed the mean weight even though it did not.\n",
        "  * Consequences:\n",
        "    * We stop production\n",
        "    * we recalibrate the machine\n",
        "    * blame the upgrade\n",
        "    * but nothing was wrong\n",
        "  * Are Type-1 errors bad?\n",
        "* Type II Error (False Negative): $H_{0}$ is actually false (mean has really changed). But, we failed to reject the Null.  \n",
        "    * Consequences:\n",
        "        * We continue production without noticing\n",
        "        * Candy. bars size over/under-filled\n",
        "        * Customers may complain\n",
        "        * Quality issues arise\n",
        "      * Are Type-II errors bad?\n",
        "* Power of the test\n",
        "  * Power = 1 - Type II error rate\n",
        "    * Our test correctly detects real changes\n",
        "* Trade-off between Type1/TypeII errors and the choice of $\\alpha$ ?\n",
        "  * You cannot minimize both errors simultaneously\n",
        "    * Lowering Type I error increase Type II error\n",
        "    * Lowering Type II increase Type I error"
      ],
      "metadata": {
        "id": "GzrE-Fn-Musr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistically Significant  (SS)\n",
        "\n",
        "A result is SS when\n",
        "\n",
        "* p-value $\\lt$ $\\alpha$\n",
        "\n",
        "Note:\n",
        "* SS does not mean\n",
        "  * effect is big\n",
        "  * result is true\n",
        "  * more important"
      ],
      "metadata": {
        "id": "8CgxXXTOIgL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of testing whether the coin fair\n",
        "\n",
        "if we want to test whether the coin (p = prob of landing Hs) we have is fair.  \n",
        "\n",
        "$$ H_0 : p = 0.5 $$\n",
        "$$ H_A : p \\ne 0.5 $$"
      ],
      "metadata": {
        "id": "bY9s-Vf_3YT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic ideas\n",
        "\n",
        "* Bernoulli Trial (Single flip)\n",
        "  * Each individuval flip is a \"Bernoulli trial\"\n",
        "  * Only two outcomes: H (Sucess) or T (failure)\n",
        "  * Probability of Hs = p (for a fair coin, p = 0.5)\n",
        "* Binomial Distribution (Multiple Independent Flips)\n",
        "  * A reference table/curve that tells you probabilities\n",
        "  * Created mathematically (not from your experiemtn)\n",
        "  * Shows what outcomes to expect IF the coin is fair (p=0.5)\n",
        "  ### Connection to Bernoulli\n",
        "    * Each of the flip is a Bernoulli trial\n",
        "    * X = number of Hs in one trial\n",
        "    * X follows a Binomial(n=100, p=0.5) distribution\n",
        "  ### What Binomial Distribution Tells You:\n",
        "    * P(X=0) = Prob of 0 Hs in 100 flips\n",
        "    * ...\n",
        "    * P(X=65) = Prob of 65 Hs in 100 flips\n",
        "    * etc.\n",
        "\n",
        "  $$ P(X = k) = C(n, k) \\times p^{k} \\times (1-p)^{(n-k)} $$\n",
        "  where $C(n,k) = \"n choose k\" = combinations\n",
        "\n",
        "* Normal Approximation (when n is large; number of times to repeat the bernoulli trial)\n",
        "\n"
      ],
      "metadata": {
        "id": "b2AOyuGKq3KK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Experiment\n",
        "  * Flip a coin = 100 times\n",
        "  * Cont the result, X = 65 Hs (example)\n",
        "  * One experiment. One Number: 65\n",
        "* Question\n",
        "  * Is this coin fair, or is it biased?\n",
        "\n",
        "# Using a pre-existing Reference Distribution\n",
        "\n",
        "  * Mathematicians already derived a reference distribution for us\n",
        "    * They derived the Binomial(n=100, p=0.5) distribution\n",
        "    * This distribution shows, \"If the coin is fair, here is likely each outcome is\"\n",
        "    * It tells us the probability of getting 0 Hs, 1Hs, ....100 Hs.\n",
        "  * If we take one result from our experiment (X = 65) and compare it with the reference\n",
        "    * Look at our pre-existing Binomial Distribution\n",
        "    * Ask: Where does my result (H=65) fall on this distribution?\n",
        "    * Find: \"Getting 65 or more Hs happens only 0.3% of the time if the coin is fair\n",
        "  * Make a decision\n",
        "    * Since 65 is unlikely under the \"fair coin\" distribution\n",
        "    * Conclude: The coin is biased\n"
      ],
      "metadata": {
        "id": "-5Hoq8yVtiWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean\n",
        "\n",
        "$$ E[[X] = \\sum k \\times P(X=k)  \\text{   for k = 0 to n} $$\n",
        "\n",
        "After working with Algebra, we get\n",
        "\n",
        "E[X] = np\n",
        "\n",
        "Example\n",
        "\n",
        "* If we flip 100 coin (n = 100)\n",
        "* Each has p = 0.5 chance of Hs\n",
        "* Expected Hs $\\mu$ = 100 * 0.5 = 50\n",
        "\n",
        "# SD\n",
        "\n",
        "$$ \\text{Var}[X] = E[X^2] - (E[X])^2 $$\n",
        "\n",
        "After working through Algebra,\n",
        "\n",
        "$$ \\text{Var}[X] = \\sqrt{np(1-p)} $$\n",
        "\n",
        "# Example\n",
        "\n",
        "* n= 100, p = 0.5\n",
        "* Variance = 100 * 0.5 * 0.5 = 25\n",
        "* SD: $\\sigma$ = $\\sqrt{25}$ = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "7xoQ5e_kAsdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As n increases, Binomial(n, p) --> Normal Distribution\n",
        "\n",
        "The limiting normal has the SAME mean (np) and variance (np(1-p))\n",
        "\n",
        "When np$\\ge$10 and n(1-p) $\\ge$ 10, he approximation is accurate enough for practical use."
      ],
      "metadata": {
        "id": "Pl0pLjLtDbdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Course setup: safe clone + cd + import path ====\n",
        "import os\n",
        "import sys\n",
        "\n",
        "REPO_URL = \"https://github.com/joelgrus/data-science-from-scratch.git\"\n",
        "REPO_DIR = \"data-science-from-scratch\"\n",
        "\n",
        "# 1. If we're *anywhere inside* the repo, move to the parent directory first\n",
        "cwd = os.getcwd()\n",
        "if REPO_DIR in cwd.split(os.sep):\n",
        "    parts = cwd.split(os.sep)\n",
        "    # Walk up until we are at .../data-science-from-scratch\n",
        "    while parts and parts[-1] != REPO_DIR:\n",
        "        parts.pop()\n",
        "    # Now go to the directory *above* the repo\n",
        "    parent_dir = os.sep.join(parts[:-1]) or \"/\"\n",
        "    os.chdir(parent_dir)\n",
        "    print(f\"Moved to parent directory: {os.getcwd()}\")\n",
        "\n",
        "# 2. Clone only if needed\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(\"Cloning repo...\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(f\"{REPO_DIR} already exists — skipping clone.\")\n",
        "\n",
        "# 3. cd into the repo (this is where you'll live most of the time)\n",
        "%cd {REPO_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtMITU0xLp5k",
        "outputId": "9e2cc8c8-1832-4e02-e43d-e054ef1e7b5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repo...\n",
            "Cloning into 'data-science-from-scratch'...\n",
            "remote: Enumerating objects: 392, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 392 (delta 107), reused 93 (delta 93), pack-reused 247 (from 1)\u001b[K\n",
            "Receiving objects: 100% (392/392), 762.39 KiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (207/207), done.\n",
            "/content/data-science-from-scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import math\n",
        "\n",
        "def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:\n",
        "  \"\"\" Returns mu and sigma corresponding to a Binomial(n, p) \"\"\"\n",
        "  mu = p * n\n",
        "  sigma = math.sqrt(p * (1-p) * n)\n",
        "  return mu, sigma\n"
      ],
      "metadata": {
        "id": "KxFd-cmR28h_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scratch.probability import normal_cdf\n",
        "# The normal cdf _is_ the probability the variable is below a threshold\n",
        "normal_probability_below = normal_cdf\n",
        "# It's above the threshold if it's not below the threshold\n",
        "def normal_probability_above(lo: float, mu: float = 0, sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is greater than lo.\"\"\"\n",
        "  return 1 - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# It's between if it's less than hi, but not less than lo\n",
        "def normal_probability_between(lo: float, hi: float, mu: float = 0,\n",
        "                               sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is between lo and hi.\"\"\"\n",
        "  return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
        "\n",
        "# It's outside if it's not between\n",
        "def normal_probability_outside(lo: float, hi: float, mu: float = 0,\n",
        "                               sigma: float = 1) -> float:\n",
        "  \"\"\"The probability that an N(mu, sigma) is not between lo and hi.\"\"\"\n",
        "  return 1 - normal_probability_between(lo, hi, mu, sigma)"
      ],
      "metadata": {
        "id": "gQu8oBiCHTJp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd8fa50d-ae1a-4d27-9fb9-1b72865c64b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Comparison"
      ],
      "metadata": {
        "id": "v9Quq4kKQGXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Interval\n",
        "\n",
        "A confidence interval (CI) provides a range of plausible values for a population parameter, such as a mean.\n",
        "\n",
        "If you compute a 95% CI for the mean weight of candy bars:\n",
        "\n",
        "$$ \\bar{x} \\pm 1.96 \\cdot \\frac{s}{\\sqrt{n}} $$\n",
        "\n",
        "This gives a range such that:\n",
        "\n",
        "If you repeated the sampling process infinitely many times, 95% of the intervals would contain the true mean μ.\n",
        "\n",
        "\n",
        "* A CI does not say “there is a 95% chance μ is in this interval.”\n",
        "* Instead: “This method captures μ in 95% of repeated experiments.”\n",
        "* The CI width reflects uncertainty. Smaller width = more precision."
      ],
      "metadata": {
        "id": "_vT3ji3AVDkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vp13NWYkZt6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F8q0RSBZZt2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose:\n",
        "* Sample mean = 247g\n",
        "    * s1 = [243.1, 250.9], s2 = [246.8, 254.2] ....  sn\n",
        "    * Each of these is a CI from a sample\n",
        "    * $I1, I2, I3, I4, ...$ from $s1, s2, s3, s4, ... $\n",
        "    * Of all these intervals 95% will contain the true mean $\\mu$ and 5% will miss. We never know which interval is correct, but th procedure succeeds 95% of the time\n",
        "\t* Standard deviation = 20g\n",
        "\t* n = 100\n",
        "\n",
        "95% CI:\n",
        "\n",
        "$247 \\pm 1.96 \\cdot \\frac{20}{10} = 247 \\pm 3.92$\n",
        "\n",
        "That is:\n",
        "\n",
        "[243.08,\\; 250.92]\n",
        "\n",
        "Because 250g is inside this interval → we fail to reject H₀ at α = 0.05.\n",
        "\n",
        "CI ↔ Hypothesis Test\n",
        "\n",
        "* A 95% CI and a two-sided hypothesis test at α = 0.05 give the same decision:\n",
        "* If the CI excludes 250 → reject H₀\n",
        "* If the CI includes 250 → fail to reject H₀\n"
      ],
      "metadata": {
        "id": "hONEmOKEWxAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CI Assumptions:\n",
        "* Independent observations (selected independent of the others)\n",
        "* Accurate Data (non biased)\n",
        "*"
      ],
      "metadata": {
        "id": "vp5vSXVJcgdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# p-Hacking\n",
        "\n",
        "With some help, you can find the \"significant\" hypothesis if you test enough hypotheses against your dataset\n",
        "\n",
        "To do good science, decide on your hypotheses before looking at the data."
      ],
      "metadata": {
        "id": "OTrKsLZ-fhKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p-Hacking\n",
        "import random\n",
        "\n",
        "from typing import List\n",
        "def run_experiment() -> List[bool]:\n",
        "  \"\"\"Flips a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
        "  return [random.random() < 0.5 for _ in range(1000)]\n",
        "\n",
        "def reject_fairness(experiment: List[bool]) -> bool:\n",
        "  \"\"\"Using the 5% significance levels\"\"\"\n",
        "  num_heads = len([flip for flip in experiment if flip])\n",
        "  return num_heads < 469 or num_heads > 531\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "experiments = [run_experiment() for _ in range(1000)]\n",
        "num_rejections = len([experiment\n",
        "                      for experiment in experiments\n",
        "                      if reject_fairness(experiment)])\n",
        "assert num_rejections == 46"
      ],
      "metadata": {
        "id": "fbjCkqnPecSG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A/B Testing\n",
        "\n",
        "Check the book/Book-Github for details"
      ],
      "metadata": {
        "id": "efZpcHWGXj4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Inference\n",
        "\n",
        "Check the book/Book-Github for details"
      ],
      "metadata": {
        "id": "fwX2uuFHXmos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nv6pjJoyCEoh"
      },
      "outputs": [],
      "source": []
    }
  ]
}